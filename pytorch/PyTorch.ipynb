{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在开始使用PyTorch时应该了解的主要元素：\n",
    "\n",
    "* PyTorch张量\n",
    "\n",
    "* 数学运算\n",
    "\n",
    "* Autograd模块\n",
    "\n",
    "* Optim模块\n",
    "\n",
    "* 神经网络模块\n",
    "\n",
    "下面让我们依次介绍这些元素吧。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、PyTorch张量\n",
    "张量只是多维数组。PyTorch中的的张量类似于numpy的ndarrays，另外，张量也可以在GPU上使用。PyTorch支持各种类型的张量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1Tensor的数据类型\n",
    "### 1.1.1 torch.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "\n",
      " b:\n",
      "tensor([2., 3., 4., 5.])\n"
     ]
    }
   ],
   "source": [
    "#指定纬度\n",
    "a = torch.FloatTensor(2,3)\n",
    "print(a)\n",
    "print(\"\\n b:\")\n",
    "\n",
    "#按照给定列表生成浮点型的Tensor\n",
    "b = torch.FloatTensor([2,3,4,5])\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 torch.IntTensor \n",
    "用于生成数据类型为整型的Tensor，传递torch.IntTensor的参数可以是一个列表，也可以是表示纬度的元组。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0]], dtype=torch.int32)\n",
      "\n",
      " b:\n",
      "tensor([5, 6, 7, 8], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "a = torch.IntTensor(2, 3)\n",
    "print(a)\n",
    "b = torch.IntTensor([5, 6, 7, 8])\n",
    "print(\"\\n b:\")\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.3 torch.rand\n",
    "用于生成数据类型为浮点型且维度指定的随机Tensor，和在Numpy中使用的numpy.rand生成随机数的方法类似，随机生成的浮点数据在0~1区间均匀分布。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7617, 0.8165, 0.5766],\n",
      "        [0.3291, 0.0191, 0.6009]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(2,3)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.4 torch.randn\n",
    "用于数据类型为浮点型且维度指定的随机Tensor，和在Numpy中使用的Numpy.randn生成的随机数的方法类似，随机生成的浮点数的取值满足均值为0，方差为1的正态分布。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.9301, -1.3113,  0.5000],\n",
      "        [ 0.1787,  0.2772, -0.5851]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(2, 3)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.5 torch.arange \n",
    "torch.range已经被弃用\n",
    "\n",
    "用于生成数据类型为浮点型且自定义开始范围和结束范围的Tensor，所以传递给torch.range的参数有三个，分别是范围的起始值，范围的结束值和步长，其中，步长用于指定从起始值到结束值得每步的数据间隔。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4, 5, 6, 7, 8, 9])\n"
     ]
    }
   ],
   "source": [
    "a = torch.arange(1, 10, 1)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.6 torch.zeros\n",
    "用于生成数据类型为浮点型且维度指定的Tensor，不过这个浮点型的Tensor中的元素全部为0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.zeros(2, 3)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Tensor的运算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 torch.mul\n",
    "将参数传递到torch.mul后返回输入参数求积的结果作为输出，参与运算的参数可以全部是Tensor数据类型的变量，也可以是Tensor数据类型的变量和标量的组合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:\n",
      "tensor([[ 4.6872e-01,  3.2202e-01,  2.4221e+00],\n",
      "        [ 8.1761e-01, -2.1217e-03, -1.1340e+00]])\n",
      "\n",
      " b:\n",
      "tensor([[-0.4322,  1.5551, -1.3506],\n",
      "        [-1.2597, -0.6036,  2.1189]])\n",
      "\n",
      "torch.mul(a,b):\n",
      "tensor([[-2.0258e-01,  5.0076e-01, -3.2714e+00],\n",
      "        [-1.0299e+00,  1.2807e-03, -2.4028e+00]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(2,3)\n",
    "print(\"a:\")\n",
    "print(a)\n",
    "\n",
    "b = torch.randn(2,3)\n",
    "print(\"\\n b:\")\n",
    "print(b)\n",
    "\n",
    "print(\"\\ntorch.mul(a,b):\")\n",
    "c = torch.mul(a, b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 torch. mm\n",
    "将参数传递到torch.mm后返回输入参数的求积结果作为输出，不过这个求积的方式和之前的torch.mul运算方式不太一样，torch.mm运用矩阵之间的乘法规则进行计算，所以被传入的参数会被当作矩阵进行处理，参数的维度自然也要满足矩阵乘法的前提条件，即前一个矩阵的行数必须和后一个矩阵的列数相等，否则不能进行计算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.0622, -2.0696],\n",
      "        [ 0.2198,  0.0640],\n",
      "        [-0.2105,  0.8796]])\n",
      "\n",
      "b:\n",
      "tensor([[-2.0049,  2.2201, -0.5509],\n",
      "        [ 0.2837, -1.5067,  1.9639]])\n",
      "\n",
      "torch.mm(a,b):\n",
      "tensor([[ 1.5425,  0.7603, -3.4794],\n",
      "        [-0.4225,  0.3916,  0.0046],\n",
      "        [ 0.6716, -1.7927,  1.8434]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(3,2)\n",
    "print(a)\n",
    "b = torch.randn(2,3)\n",
    "print(\"\\nb:\")\n",
    "print(b)\n",
    "\n",
    "c = torch.mm(a, b)\n",
    "print(\"\\ntorch.mm(a,b):\")\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.3 torch.mv\n",
    "将参数传递到torch.mv后返回输入参数的求积结果作为输出，torch.mv运用矩阵与向量之间的乘法法则进行计算，被传入的参数中第1个参数代表矩阵，第2个参数代表向量，顺序不能颠倒。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:\n",
      "tensor([[-0.2934,  0.0307, -0.2456],\n",
      "        [-1.1221, -1.3581, -0.9236]])\n",
      "\n",
      "b:\n",
      "tensor([-1.7865, -0.0162,  0.2873])\n",
      "\n",
      "torch.mv(a,b):\n",
      "tensor([0.4530, 1.7612])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(2,3)\n",
    "print(\"a:\")\n",
    "print(a)\n",
    "\n",
    "b = torch.randn(3)\n",
    "print(\"\\nb:\")\n",
    "print(b)\n",
    "\n",
    "c = torch.mv(a,b)\n",
    "print(\"\\ntorch.mv(a,b):\")\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、数学运算\n",
    "与numpy一样，科学计算库非常重要的一点是能够实现高效的数学功能。而PyTorch提供了一个类似的接口，可以使用200个以上的数学运算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.FloatTensor([2])\n",
    "b = torch.FloatTensor([3])\n",
    "a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "还可以在定义的PyTorch张量上执行各种矩阵运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7731, -0.5575,  1.4147],\n",
       "        [-0.5859,  0.4719, -1.6255],\n",
       "        [-0.5798,  0.4868, -0.9457]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = torch.randn(3,3)\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7731, -0.5859, -0.5798],\n",
       "        [-0.5575,  0.4719,  0.4868],\n",
       "        [ 1.4147, -1.6255, -0.9457]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.t()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 三、Autograd模块\n",
    "PyTorch使用了一种叫做自动微分的技术。也就是说，它会有一个记录我们所有执行操作的记录器，之后再回放记录来计算我们的梯度。这一技术在构建神经网络时尤其有效，因为我们可以通过计算前路参数的微分来节省时间。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-a1e3f2044ad3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequires_grad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_x' is not defined"
     ]
    }
   ],
   "source": [
    "x = Variable(train_x)\n",
    "y = Variable(train_y, requires_grad = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 四、Optim模块\n",
    "torch.optim是一个实现各种优化算法的模块，用于构建神经网络。它支持大多数常用的方法，因此我们不必从头开始构建它们。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
